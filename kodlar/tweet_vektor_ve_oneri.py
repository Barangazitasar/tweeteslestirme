import pandas as pd
import numpy as np
from gensim.models import Word2Vec

# ğŸ”¹ Basit tokenizer (nltk yerine)
def tokenize(text):
    return text.lower().split()

# ğŸ”¹ Ortalama vektÃ¶r hesabÄ±
def ortalama_vektor(tweet, model):
    if not tweet:
        return np.zeros(model.vector_size)
    vektorler = [model.wv[word] for word in tweet if word in model.wv]
    if vektorler:
        return np.mean(vektorler, axis=0)
    else:
        return np.zeros(model.vector_size)

# ğŸ”¹ Veriyi oku
df = pd.read_csv("temizlenmis_tweetler_stop.csv")
df["TemizTweet_Stop"] = df["TemizTweet_Stop"].fillna("")

# ğŸ”¹ Tweetleri tokenize et
tweet_tokens = [tokenize(tweet) for tweet in df["TemizTweet_Stop"]]

# ğŸ”¹ EÄŸitilmiÅŸ Word2Vec modelini yÃ¼kle
model = Word2Vec.load("word2vec_model.model")

# ğŸ”¹ TÃ¼m tweetlerin ortalama vektÃ¶rlerini hesapla
vektorler = np.array([ortalama_vektor(tweet, model) for tweet in tweet_tokens])

# ğŸ”¹ Belirli bir tweet'e gÃ¶re en benzerleri bul
def benzer_tweetleri_getir(index, k=5):
    secilen = vektorler[index]
    benzerlikler = np.dot(vektorler, secilen) / (
        np.linalg.norm(vektorler, axis=1) * np.linalg.norm(secilen) + 1e-10
    )
    en_benzer_indeksler = np.argsort(benzerlikler)[::-1][1:k+1]
    return en_benzer_indeksler

# ğŸ”¹ Ã–rnek: 10. tweet'e en benzer 5 tweet
index = 10
print(f"ğŸ“Œ SeÃ§ilen tweet: {df['TemizTweet_Stop'][index]}")
print("\nğŸ” Benzer tweetler:")
for i in benzer_tweetleri_getir(index):
    print(f"- {df['TemizTweet_Stop'][i]}")
